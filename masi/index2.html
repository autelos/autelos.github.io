<!DOCTYPE html>
<html>
<head>
    <title>masi</title>
  <meta charset="utf-8" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Literata:regular,italic,bold|Roboto+Mono:wght@450">
  <link rel="stylesheet" type="text/css" href="/masi/theme/css/style.css">

</head>

<body>
  <section id="nav">
    <header>
      <h1><a href="/masi/">masi</a></h1>
    </header>
    <nav id="menu"><ul>
      <li><a href="/masi/about/">/about</a></li>
      <li><a href="/masi/category/annotator.html">/annotator</a></li>
      <li><a href="/masi/category/notes.html">/notes</a></li>
      <li><a href="/masi/category/sounds.html">/sounds</a></li>
      <li><a href="/masi/ul">//ul</a></li>
      <li><a href="/masi/field-recording">//field recording</a></li>
      <li><a href="/masi/pd">//pd</a></li>
      <li><a href="/masi/modules">//modules</a></li>
    </ul></nav>
  </section>

  <section id="content">
  <div class="date">2020.06.16   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/train-to-allgau/">train to allgäu</a></h2>

  <div class="sf" id="2020-06-16_0133.ogg"></div>

  <div class="entry-content">
  <p><img alt="pd in the train" src="/masi/media/2020-06-16_083333.jpg" /></p>
<p>a space in-between, a space on the way. mediating the loud train ride through a macbook microphone and earlier piano sample to test functionality of the patch accidentally re-situates the listening experience as active and real-time.</p>
<blockquote>
<p>the presence of everything, nothing shouts importance ... quiet is quieting ... (Gordon Hempten)</p>
</blockquote>
  </div>
  <div class="date">2020.05.14  /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/khg-t02/">KHG T02</a></h2>

  <div class="sf" id="2020-05-14_KHG-1.ogg"></div>
  <div class="sf" id="2020-05-14_KHG-3.ogg"></div>
  <div class="sf" id="2020-05-14_KHG-4.ogg"></div>
  <div class="sf" id="2020-05-14_KHG-5.ogg"></div>
  <div class="sf" id="2020-05-14_KHG-6.ogg"></div>
  <div class="sf" id="2020-05-14_KHG-8.ogg"></div>

  <div class="entry-content">
  <p><img alt="khg setup" src="/masi/media/2020-05-14_161030.jpg" /></p>
<p>Selected recorded improvisations from a sunny morning and afternoon in the Hl. Johannes XXIII church.</p>
  </div>
  <div class="date">2020.05.11   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/buffer-looper-on-launchpad-d01/">Buffer Looper on Launchpad D01</a></h2>

  <div class="sf" id="2020-05-11_2200_P17.ogg"></div>

  <div class="date">2020.01.23   <a href="/masi/pd">pd</a>  <a href="/masi/modules">modules</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/figure-ground-delayline-modulator/">Figure-Ground Delayline Modulator</a></h2>

  <div class="sf" id="2020-02-05_225924-mawamama-t01.ogg"></div>

  <div class="entry-content">
  <p>the length of a sound-object figure modulates the length of a delayline<br />
sounds received are fed back at varying, controllable, later times<br />
varying the change in speed pitches the sound being fed back</p>
<p><img alt="screenshot" src="/masi/patches/figure-ground-delayline-modulator.pd.png#pd-screenshot" /><br />
<a href="/masi/patches/figure-ground-delayline-modulator.pd">figure-ground-delayline-modulator.pd</a><br />
<a href="/masi/patches/figure-ground-delayline-modulator-help.pd">figure-ground-delayline-modulator-help.pd</a></p>
  </div>
  <div class="date">2020.07.07  /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/orgelstunde-st-michael-brusselerplatz/">Orgelstunde, St. Michael, Brüsselerplatz</a></h2>

  <div class="sf" id="2020-07-07_BrüsselerPlatzOrgel_1.mp3"></div>
  <div class="sf" id="2020-07-07_BrüsselerPlatzOrgel_3.mp3"></div>

  <div class="entry-content">
  <video src="/masi/media/2020-07-07_191631.mp4#vertical" controls></video>

<video src="/masi/media/2020-07-07_185128.mp4" controls></video>

<p>A serendipitous organ hour at the St. Michaels church in Brüsseler Platz. Standing in the middle of the church, kids play outside, filter through, reverberate. Victor switches the organ on, a low hum, a deep breath fills the space. Soft flutes tumble in, strings and bass sounds smoothly drift into eachother.</p>
<p>Victor invites us upstairs for an organ hour with the <em>Baroque Synthesizer</em>, displaying the voice options assigned to three keyboards, foot pedals, volume pedal, flexible coupling.</p>
<p>for next time:</p>
<ul>
<li>try a two stereo-mic setup:<ul>
<li>in front of organ (in player's position) to capture wide stereo image</li>
<li>in middle of church, for reverb, outside sound, trumpet</li>
</ul>
</li>
<li>felix free to move around the space with trumpet</li>
</ul>
  </div>
  <div class="date">2020.07.06  /<a href="/masi/category/annotator.html">annotator</a></div>
  <h2><a href="/masi/annotator-descriptiondolist/">annotator description/dolist</a></h2>


  <div class="entry-content">
  <p>_ archive/annotator presents recordings with possibly defined start position, end position, highlighted/annotate regions, and regions marked for removal (which are skipped over). it offers an easy collaborative in-browser possibility of annotatating and non-destructively presenting snippets in the context of their longer recordings.</p>
<p>how to use:</p>
<ul>
<li>click on recording to load soundfile, waveform, and start playing</li>
<li>click and drag on waveform to create and select region</li>
<li>type to annotate (some commands are interpreted):</li>
<li><code>start</code><ul>
<li>sets start position</li>
</ul>
</li>
<li><code>end</code><ul>
<li>sets end position</li>
</ul>
</li>
<li><code>rm</code><ul>
<li>skips region with fade-in/fade-out</li>
<li>currently set to 500 ms fade</li>
<li>[ ] add variable fade-in/fade-out times<ul>
<li>eg. <code>rm 500</code></li>
</ul>
</li>
<li>[ ] add crossfade</li>
</ul>
</li>
</ul>
<p>Note: adding/changing annotations is currently password-protected</p>
  </div>
  <div class="date">2020.07.04  /<a href="/masi/category/notes.html">notes</a></div>
  <h2><a href="/masi/emergence-in-audibly-structured-soundscape/">Emergence in audibly-structured soundscape</a></h2>


  <div class="entry-content">
  <?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.44.0 (20200408.0750)
 -->
<!-- Title: emergence Pages: 1 -->
<svg width="491pt" height="104pt"
 viewBox="0.00 0.00 490.76 103.58" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 99.58)">
<title>emergence</title>
<!-- audiosystem -->
<g id="node1" class="node">
<title>audiosystem</title>
<ellipse fill="none" stroke="black" cx="55.25" cy="-64" rx="55.49" ry="18"/>
<text text-anchor="middle" x="55.25" y="-60.3" font-family="Times,serif" font-size="14.00">audiosystem</text>
</g>
<!-- imprint in space -->
<g id="node2" class="node">
<title>imprint in space</title>
<ellipse fill="none" stroke="black" cx="214.73" cy="-64" rx="68.49" ry="18"/>
<text text-anchor="middle" x="214.73" y="-60.3" font-family="Times,serif" font-size="14.00">imprint in space</text>
</g>
<!-- audiosystem&#45;&gt;imprint in space -->
<g id="edge1" class="edge">
<title>audiosystem&#45;&gt;imprint in space</title>
<path fill="none" stroke="black" d="M110.89,-64C119.12,-64 127.75,-64 136.35,-64"/>
<polygon fill="black" stroke="black" points="136.42,-67.5 146.42,-64 136.42,-60.5 136.42,-67.5"/>
</g>
<!-- field recorder -->
<g id="node4" class="node">
<title>field recorder</title>
<ellipse fill="none" stroke="black" cx="400.87" cy="-18" rx="57.69" ry="18"/>
<text text-anchor="middle" x="400.87" y="-14.3" font-family="Times,serif" font-size="14.00">field recorder</text>
</g>
<!-- audiosystem&#45;&gt;field recorder -->
<g id="edge5" class="edge">
<title>audiosystem&#45;&gt;field recorder</title>
<path fill="none" stroke="black" d="M93.56,-50.86C109.65,-45.71 128.8,-40.27 146.49,-37 208.99,-25.45 281.39,-20.88 332.76,-19.1"/>
<polygon fill="black" stroke="black" points="333.18,-22.58 343.07,-18.76 332.96,-15.59 333.18,-22.58"/>
</g>
<!-- perciever&#45;performer -->
<g id="node3" class="node">
<title>perciever&#45;performer</title>
<ellipse fill="none" stroke="black" cx="400.87" cy="-72" rx="81.79" ry="18"/>
<text text-anchor="middle" x="400.87" y="-68.3" font-family="Times,serif" font-size="14.00">perciever&#45;performer</text>
</g>
<!-- imprint in space&#45;&gt;perciever&#45;performer -->
<g id="edge2" class="edge">
<title>imprint in space&#45;&gt;perciever&#45;performer</title>
<path fill="none" stroke="black" d="M281.69,-60.36C294.52,-60.67 308.09,-61.2 321.27,-61.9"/>
<polygon fill="black" stroke="black" points="321.09,-65.39 331.27,-62.47 321.48,-58.41 321.09,-65.39"/>
</g>
<!-- imprint in space&#45;&gt;field recorder -->
<g id="edge6" class="edge">
<title>imprint in space&#45;&gt;field recorder</title>
<path fill="none" stroke="black" d="M265.08,-51.67C289.81,-45.49 319.83,-37.99 345.26,-31.64"/>
<polygon fill="black" stroke="black" points="346.26,-35 355.12,-29.18 344.57,-28.21 346.26,-35"/>
</g>
<!-- perciever&#45;performer&#45;&gt;audiosystem -->
<g id="edge3" class="edge">
<title>perciever&#45;performer&#45;&gt;audiosystem</title>
<path fill="none" stroke="black" d="M339.45,-83.96C287.95,-92.39 212.07,-100.6 146.49,-91 131.91,-88.87 116.41,-84.89 102.44,-80.63"/>
<polygon fill="black" stroke="black" points="103.17,-77.19 92.58,-77.5 101.05,-83.86 103.17,-77.19"/>
</g>
<!-- perciever&#45;performer&#45;&gt;imprint in space -->
<g id="edge4" class="edge">
<title>perciever&#45;performer&#45;&gt;imprint in space</title>
<path fill="none" stroke="black" d="M320.3,-75.24C308.34,-74.82 296.09,-74.25 284.38,-73.53"/>
<polygon fill="black" stroke="black" points="284.45,-70.03 274.25,-72.88 284,-77.02 284.45,-70.03"/>
</g>
</g>
</svg>

<p><em>Figure: Emergence in place-language improvisation</em></p>
<p>modules for real-time composition of audibly-structured soundscape</p>
<p>A theoretical counterpart to the notion of audible ecosystems is the idea of emergent sound structures. The macroform emerges from interactions of the microforms.</p>
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.44.0 (20200408.0750)
 -->
<!-- Title: macroform_from_microform Pages: 1 -->
<svg width="343pt" height="279pt"
 viewBox="0.00 0.00 342.89 279.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 275)">
<title>macroform_from_microform</title>
<g id="clust2" class="cluster">
<title>cluster_0</title>
<path fill="transparent" stroke="black" stroke-dasharray="1,5" d="M183.89,-8C183.89,-8 314.89,-8 314.89,-8 320.89,-8 326.89,-14 326.89,-20 326.89,-20 326.89,-215 326.89,-215 326.89,-221 320.89,-227 314.89,-227 314.89,-227 183.89,-227 183.89,-227 177.89,-227 171.89,-221 171.89,-215 171.89,-215 171.89,-20 171.89,-20 171.89,-14 177.89,-8 183.89,-8"/>
<text text-anchor="middle" x="249.39" y="-211.8" font-family="Times,serif" font-size="14.00">real&#45;time audio processor</text>
</g>
<!-- space -->
<g id="node1" class="node">
<title>space</title>
<ellipse fill="none" stroke="black" cx="145.89" cy="-253" rx="30.59" ry="18"/>
<text text-anchor="middle" x="145.89" y="-249.3" font-family="Times,serif" font-size="14.00">space</text>
</g>
<!-- perciever&#45;performer -->
<g id="node2" class="node">
<title>perciever&#45;performer</title>
<ellipse fill="none" stroke="black" cx="81.89" cy="-178" rx="81.79" ry="18"/>
<text text-anchor="middle" x="81.89" y="-174.3" font-family="Times,serif" font-size="14.00">perciever&#45;performer</text>
</g>
<!-- space&#45;&gt;perciever&#45;performer -->
<g id="edge1" class="edge">
<title>space&#45;&gt;perciever&#45;performer</title>
<path fill="none" stroke="black" d="M128.09,-237.92C118.4,-228.32 106.69,-215.34 97.37,-204.01"/>
<polygon fill="black" stroke="black" points="100.05,-201.75 91.08,-196.12 94.58,-206.12 100.05,-201.75"/>
</g>
<!-- input -->
<g id="node3" class="node">
<title>input</title>
<ellipse fill="none" stroke="black" cx="209.89" cy="-178" rx="28.7" ry="18"/>
<text text-anchor="middle" x="209.89" y="-174.3" font-family="Times,serif" font-size="14.00">input</text>
</g>
<!-- space&#45;&gt;input -->
<g id="edge2" class="edge">
<title>space&#45;&gt;input</title>
<path fill="none" stroke="black" d="M162.31,-237.62C165.91,-234.24 169.62,-230.58 172.89,-227 179.77,-219.47 186.75,-210.76 192.76,-202.84"/>
<polygon fill="black" stroke="black" points="195.69,-204.77 198.85,-194.66 190.07,-200.59 195.69,-204.77"/>
</g>
<!-- perciever&#45;performer&#45;&gt;space -->
<g id="edge4" class="edge">
<title>perciever&#45;performer&#45;&gt;space</title>
<path fill="none" stroke="black" d="M102.11,-195.5C111.41,-204.91 122.14,-216.9 130.75,-227.4"/>
<polygon fill="black" stroke="black" points="128.17,-229.78 137.13,-235.44 133.65,-225.43 128.17,-229.78"/>
</g>
<!-- perciever&#45;performer&#45;&gt;input -->
<g id="edge3" class="edge">
<title>perciever&#45;performer&#45;&gt;input</title>
<path fill="none" stroke="black" d="M163.89,-178C166.23,-178 168.56,-178 170.9,-178"/>
<polygon fill="black" stroke="black" points="171.14,-181.5 181.14,-178 171.14,-174.5 171.14,-181.5"/>
</g>
<!-- process -->
<g id="node4" class="node">
<title>process</title>
<ellipse fill="none" stroke="black" cx="216.89" cy="-106" rx="37.09" ry="18"/>
<text text-anchor="middle" x="216.89" y="-102.3" font-family="Times,serif" font-size="14.00">process</text>
</g>
<!-- input&#45;&gt;process -->
<g id="edge5" class="edge">
<title>input&#45;&gt;process</title>
<path fill="none" stroke="black" d="M211.62,-159.7C212.39,-151.98 213.32,-142.71 214.18,-134.11"/>
<polygon fill="black" stroke="black" points="217.67,-134.4 215.18,-124.1 210.7,-133.71 217.67,-134.4"/>
</g>
<!-- output -->
<g id="node5" class="node">
<title>output</title>
<ellipse fill="none" stroke="black" cx="248.89" cy="-34" rx="33.29" ry="18"/>
<text text-anchor="middle" x="248.89" y="-30.3" font-family="Times,serif" font-size="14.00">output</text>
</g>
<!-- process&#45;&gt;output -->
<g id="edge6" class="edge">
<title>process&#45;&gt;output</title>
<path fill="none" stroke="black" d="M224.64,-88.05C228.33,-79.97 232.84,-70.12 236.96,-61.11"/>
<polygon fill="black" stroke="black" points="240.24,-62.34 241.22,-51.79 233.88,-59.43 240.24,-62.34"/>
</g>
<!-- output&#45;&gt;space -->
<g id="edge7" class="edge">
<title>output&#45;&gt;space</title>
<path fill="none" stroke="black" d="M255.3,-51.74C268.24,-88.67 292.61,-177.78 247.89,-227 239.43,-236.31 210.46,-242.85 185.54,-246.9"/>
<polygon fill="black" stroke="black" points="184.89,-243.45 175.54,-248.43 185.95,-250.37 184.89,-243.45"/>
</g>
</g>
</svg>

<p><em>Figure: Emergent macroform from microform interaction</em></p>
<p>A real-time composition, to let "the musical (macro-level) structure emerge from sound itself and its internal organization (micro-level)." <sup id="fnref:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup></p>
<p>Selections from <em>Analysing Audible Ecosystems and Emergent Sound Structures in DiScipio’s Music</em> (Renaud Meric, Makis Solomos)<sup id="fnref2:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup> :</p>
<blockquote>
<p>While  composing  with  an  ecosystemic  approach,  the  composer  creates  an  audio system that interacts with the environment (i.e. space). This space, in which and from which music emerges, is also the listener’s space. Thus what emerges is the result of a confrontation between  the  listener’s  cognitive  system and  the  audio  system  used  in  the  musical  work.  The emergent  sound  is  difficult  to  define:  its  general  outline  is  unpredictable  and  unstable;  it  is dependent on a dynamic musical space, which is constructed by active listening and an active audio  system  simultaneously.</p>
<p>focusing on the ephemeral moment in which music emerges  in  the  interaction  between  the  listener  and  the  product  of  the  audio  system  inside  a specific space.</p>
<p>in reality, we don’t listen to sound but to its own “imprint” (empreinte), in the sense of the word developed by Georges Didi-Huberman (2008).</p>
<p>in  his  own  music, Di  Scipio  opted  for  complex  dynamic  systems:  “Chaos  and  the dynamics of complex systems, as accessible with iterated numerical processes, represented for me a way to compose small sonic units such that a higher-level sonority would manifest itself in the process” (Di Scipio inAnderson, 2005)</p>
<p>In one of his first articles (Di Scipio, 1994), he elaborated a “theory of sonological  emergence”,  whereby  form  (macroform)  is  viewed  as  “a  process  of  timbre formation” (Di Scipio, 1994: 205)</p>
<p>The  idea  of  emergent  sound  structures  is  related  to  the  elaboration  of  a sub-symbolic theory.  In  the “theory  of  sonological  emergence”,  the  emergence  of  a  higher level  should happen  through  grains  and  samples,  neither  of  which  are  symbols,  as  they  are  located  on  a low level (cf. Di Scipio, 1994: 207). With composed interactions (cf. infra), Di Scipio puts the interaction at the signal level: all the information exchanges have a sonic nature (cf. Di Scipio, 2003:  272).  We  can  draw  a  parallel  between  this  strategy  and  the  model  of  emergence  in cognitive  science.  To  the  question  “What  is  cognition?”  the  “computationalist”  model answers “Data processing: the manipulation of symbols from rules” (Varela, 1996: 42), while the  emergence  model  answers  “The  emergence  of  global  states  in  a  network  of  simple components” (Varela, 1996: 77). Regarding music, the issue at stake here is as follows: if we want the higher level (the macroform) to appear as an emergence and not as an independent construction,  we  have  to  work  only  at  the  lower  level,  abandoning  the  intermediate  level, which is the level of symbols.</p>
<p>According to emergence theory, the emergence of sound structures is possible because of the fact that the composer develops systems (in the sense of cybernetics) close to living systems, which are characterized by their capacity for auto-organization</p>
</blockquote>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p><a href="https://hal.archives-ouvertes.fr/hal-01202885/document">Renaud Meric, Makis Solomos: Analysing Audible Ecosystems and Emergent Sound Structures in DiScipio’s Music</a>&#160;<a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:1" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>
  </div>
  <div class="date">2020.06.27  /<a href="/masi/category/notes.html">notes</a></div>
  <h2><a href="/masi/listening-to-tim-shaw-on-listening/">listening to tim shaw on listening</a></h2>

  <div class="sf" id="2020-06-27_211535_mb-fan.ogg"></div>

  <div class="entry-content">
  <p>notes while listening to <a href="https://www.mixcloud.com/resonanceextra/the-field-recording-show-8-wandering-sunday-14th-june-2020/">tim shaw on listening and field recording</a></p>
<ul>
<li>indeterminancy, uncertainty</li>
<li>studio composiiton with recorded sound as medium</li>
<li>recording environmental sound, much richer to practice responding to specific sites/themes outside of studio</li>
<li>listening being the key practice of the work</li>
<li>field recording not as a documentary of one place to another<ul>
<li>more as live, performative</li>
</ul>
</li>
<li>traditionally: go somewhere with mics, sit, press record, bring it back to studio, edit/layer, (infinite amnt of things</li>
<li>performativity: walking to the site, setting up, gestures aren't visible. dislocation between making and presentation. how to fold together?<ul>
<li>record, compose, improvise with the soundscapes that move through</li>
<li>delete recordings at the end of the walk<ul>
<li>flatten presentation and process, all mistakes like handling noise</li>
</ul>
</li>
</ul>
</li>
<li>field recording as act of performance</li>
<li>headphones allow dynamics to come-in - am i hearing it in the world or in real time?</li>
<li>shifting time/memory</li>
<li>start with omni-directional mics, then take recordings using contact/hydro/electromic</li>
<li>system is malleable and shifting, like the sound-scape, always shifting, indeterminancy to them</li>
<li>i always try to carry a recorder on me, i decide to start when something interests me, finding interesting resonant spaces, or attach a contact mic to</li>
<li>starts by walking and seeking with the ear and eye</li>
<li>how long do you let it roll for? as composition in itself,</li>
<li>it's not about archiving, possesion, it's about the process, and the making and the act of it is often more interesting than the recording itself</li>
<li>'i'm very bad at working in a studio, on a computer..'</li>
<li>once the recording hits the computer ,those ossibilities freeze me, personally find it difficult to jusitify those decisions</li>
<li>using this process to learn the space, how does it react? so it's expansive - what ar eth possibilites, int he most holistic way?</li>
<li>not going into a space with too many ideas, being open to the unpredictability</li>
<li>openness, allowing those unexpected events to be just as meaningful</li>
</ul>
  </div>
  <div class="date">2020.06.26   <a href="/masi/ul">ul</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/mnmlma/">mnmlma</a></h2>

  <div class="sf" id="2020-06-26_141933_ma-iphone-piano.ogg"></div>
  <div class="sf" id="2020-06-26_170559_mnml-ma-piano-2.ogg"></div>

  <div class="entry-content">
  <p>testing the patch running running simply on iphone using built-in mic. the lightness and lack of cable connections afford an intuitive movement of the integrated mic as dry/wet modulation.</p>
<pre><code>tapeshift~ = pitch -12, window ~100, delay ~100
process = adc~:tapeshift~:dac~
</code></pre>
  </div>
  <div class="date">2020.06.25   <a href="/masi/ul">ul</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/feedback-matrix/">feedback matrix</a></h2>

  <div class="sf" id="2020-06-24_110512_feedback-1.ogg"></div>
  <div class="sf" id="2020-06-24_110956_feedback-2.ogg"></div>

  <div class="date">2020.06.24  /<a href="/masi/category/notes.html">notes</a></div>
  <h2><a href="/masi/recording-soundscapes/">recording soundscapes</a></h2>


  <div class="entry-content">
  <p>attempting to capture soundscapes of a "genuine but ephemeral set of circumstances existing in a precise moment of time," rather than soundscapes "meticulously fabricated and controlled in the vacuum of an audio editor".<sup id="fnref:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup></p>
<blockquote>
<p>actual events from a specific time and place ... a moment’s explicit actuality and serendipitous fragility. (Swift 8)</p>
<p>... a soundscape is not simply a sum of all these sounds; rather it is a particular subset filtered through the context of a given environmental condition (Swift 6)</p>
</blockquote>
<p>Curiously, wishing to capture these events often blocks or these events from occurring. This could be an example of the observer effect, a "common phenomenon where the act of observation can alter the situation being observed." (Swift 3) Perhaps the psychic attention to recording takes valuable attention away from the actual act, a moment of flow, a sort of reset.</p>
<p>Autotelic free play on an instrument -&gt; maybe a moment, groove, emerges - though to capture this! -&gt; stop playing, set up recorder, try to find it again, takes some time, energy is distracted, and the recording then captures this difference and distraction, not the original moment of free play and discovery.</p>
<p>Several strategies have been considered:</p>
<ul>
<li>a recorder ready to start at the click of a button (requiring minimal attention)</li>
<li>a recorder always running</li>
<li>a buffer recorder (capturing the last x-seconds, after the fact)</li>
</ul>
<p>Setting these to run still requires some forethought, whereas the moments occur seemingly unexpectedly/unpredictably, and most notably while not recording. A possible possible solution is to intrinsically integrate the recorder into the sound ecosystem so that recording is a seamless act with listening while using the system.</p>
<blockquote>
<p>One of Bernie Krause's tenets is that sounds should experienced in the context of their environment rather than attempting to isolate the sound. (Swift 10)</p>
</blockquote>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>Swift&#160;<a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>
  </div>
  <div class="date">2020.06.23  /<a href="/masi/category/annotator.html">annotator</a></div>
  <h2><a href="/masi/inverting-images-pd-screenshots/">inverting images (pd screenshots)</a></h2>


  <div class="entry-content">
  <p>tiny markup in markdown allows for easy client-side image-inverting</p>
<p>CSS:</p>
<pre><code class="css">img[src$='#pd-screenshot'] {
  filter: invert();
  mix-blend-mode: screen;
}
</code></pre>

<p>Markdown:</p>
<pre><code class="markdown">![alt]({static}/patches/demo.pd.png#pd-screenshot)
</code></pre>
  </div>
  <div class="date">2020.06.20   <a href="/masi/field-recording">field recording</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/allgau-waydown/">allgäu waydown</a></h2>

  <div class="sf" id="2020-06-20_084248.ogg"></div>
  <div class="sf" id="2020-06-20_084248[vm].ogg"></div>
  <div class="sf" id="2020-06-20_084726.ogg"></div>
  <div class="sf" id="2020-06-20_090718.ogg"></div>

  <div class="date">2020.06.20  /<a href="/masi/category/annotator.html">annotator</a></div>
  <h2><a href="/masi/file-management/">file management</a></h2>


  <div class="entry-content">
  <ul>
<li>[x] rename files to date-created timestamp</li>
<li>compress files to light, web-friendly version for archive</li>
<li>[x] sound: .wav to .ogg</li>
<li>[ ] sound: .wav to .mp3 (for ios)</li>
<li>[ ] video: .* to 1280x720 .mp4<ul>
<li>[ ] option to change playback speed and set+save default playspeed</li>
</ul>
</li>
<li>backup orignals elsewhere</li>
</ul>
<p>Generally, the archive/annotator should display a light, web-friendly version of the files for viewing, and store the originals elsewhere. Part of this is a shell script that turns a folder of .wavs into .ogg:</p>
<pre><code class="bash">#!/bin/sh

#patterns matching nothing should disappear...
shopt -s nullglob

#rename *.WAV to *.wav
for f in *.WAV; do
  mv &quot;$f&quot; &quot;${f%.*}.wav&quot;
done

#rename *.WAV to YYYY-MM-DD_HHMMSS-*.wav
for f in *.wav; do
  mv -n &quot;$f&quot; &quot;$(date -r &quot;$f&quot; +&quot;%Y-%m-%d_%H%M%S-${f%.*}&quot;).wav&quot;
done

mkdir &quot;ogg&quot;
mkdir &quot;converted&quot;

#convert *.wav to .ogg
for f in *.wav; do
  ffmpeg -i &quot;$f&quot; &quot;ogg/${f%.*}.ogg&quot;
  mv &quot;$f&quot; &quot;converted/$f&quot;
done
</code></pre>

<p>save as wav-to-ogg.sh then in terminal type <code>sudo cdmod -x wav-to-ogg.sh</code> and to run type <code>./wav-to-ogg.sh</code></p>
<p>and here's a command to list all of the .ogg files in a directory (handy for inserting into these markdown posts):</p>
<pre><code class="bash">oggFiles=&quot;&quot;; for i in *.ogg; do oggFiles+=&quot;$i, &quot;; done; echo $oggFiles
</code></pre>

<p>A similar script will be used for compressing videos. Here though there is the question of how to deal with the slow-motion recordings (120fps captured on iPhone 5s). Maybe the annotator shows the fps and exposes the option to change playback speed, with the last-selected setting sticking?</p>
  </div>
  <div class="date">2020.06.19   <a href="/masi/pd">pd</a>  <a href="/masi/modules">modules</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/5d-routing-matrix/">5D routing matrix</a></h2>


  <div class="entry-content">
  <p>A 5D routing matrix for PD affords programatic/instruction-based access to conduct signal routing on-the-fly with variable destinations, fade-time, and scheduling (wait x-ms first).</p>
<p>Syntax:</p>
<pre><code>[; route &lt;out&gt; &lt;in&gt; &lt;value&gt; &lt;ms-to-fade&gt; &lt;ms-to-wait&gt;(
</code></pre>

<p>This effectively decouples the patching interface from the PD GUI, allowing control to be given to, ie., the MobMuPLat touchscreen interface, which implements a grid control and 3 sliders (value, ms-to-fade, ms-to-wait).</p>
<p>This also exposes the potential for live-coding/text-based triggering, ie:</p>
<pre><code>[x]
|
[metro 100]
|
[; route &lt;dac~&gt; &lt;adc~ 1&gt; 1 10 0; r &lt;dac~&gt; &lt;adc~ 1&gt; 0 10 20(
[x]
|
[metro 101]
|
[; route &lt;dac~&gt; &lt;adc~ 2&gt; 1 10 0; r &lt;dac~&gt; &lt;adc~ 2&gt; 0 10 20(
</code></pre>
  </div>
  <div class="date">2020.06.19   <a href="/masi/field-recording">field recording</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/in-the-rain/">in the rain</a></h2>

  <div class="sf" id="2020-06-19_1935.ogg"></div>
  <div class="sf" id="2020-06-19_1939.ogg"></div>
  <div class="sf" id="2020-06-19_1954.ogg"></div>

  <div class="entry-content">
  <p><img alt="rain setup" src="/masi/media/2020-06-19_183336.jpg" /></p>
  </div>
  <div class="date">2020.06.18   <a href="/masi/field-recording">field recording</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/allgau/">allgäu</a></h2>

  <div class="sf" id="2020-06-18_1124.ogg"></div>
  <div class="sf" id="2020-06-18_1232.ogg"></div>
  <div class="sf" id="2020-06-18_1233.ogg"></div>
  <div class="sf" id="2020-06-18_1238.ogg"></div>
  <div class="sf" id="2020-06-18_1240.ogg"></div>
  <div class="sf" id="2020-06-18_1701.ogg"></div>
  <div class="sf" id="2020-06-18_1805.ogg"></div>

  <div class="date">2020.06.18  /<a href="/masi/category/notes.html">notes</a></div>
  <h2><a href="/masi/archiving-process/">archiving process</a></h2>


  <div class="entry-content">
  <p>(voice memo transcription, need to clean)</p>
<p>the archiving process is to have the original raw file, with maybe some markers at the beginning fo the file to talk in what the context of the thing is (first section is meta description). to audition, drop it into a folder that compresses the original file, drops the original onto a hard drive. and it's available for audition in the annotator. layers to configure/toggle:</p>
<p>-timestamp<br />
-place<br />
-mark points of time/regions<br />
    -tag/make notes on these markers</p>
<p>That's an annotation added in the process of reviewing. In the process of making/creating the moment you can easily make a marker or start and end a region, which saves some time, then when listening back you already have a place to start watching/listening.</p>
<p>In addition to the manually entered annotation, any interactions with the patches are logged with a line which is the information-preserved-transformation of that interaction. so the interaction is say: route the mic to the speaker, fade up in 10 secs to 50%, do that in first in 5 seconds. this is a simple single line instruction, and this is written down in that way, possibly also as a human-readable, possibly easy to type, format. and this is saved as a log file and can also be toggled, shown on and off in the annotations.</p>
<p>the benefit of also keeping track of all these digital interactions as instructions is one has the easy possibility to change later. what would have happen if we didn't trigger this? so you can remix it later by running it through the patch again, in real time, in this case loading the original file.</p>
<p>the patch saves three files:<br />
-text file: log and annotations<br />
-sound: raw, straight from the microphone<br />
-sound: from patch, exactly what's sent to speakers</p>
<p>with the first two elements, we can recreate the third file, from the list of log instructions. then it can be revisited.</p>
  </div>
  <div class="date">2020.06.18  /<a href="/masi/category/notes.html">notes</a></div>
  <h2><a href="/masi/transcriptions-to-try/">transcriptions to try</a></h2>


  <div class="entry-content">
  <p>transcribed from pocketbook in reverse chronological order</p>
<ul>
<li>[x] 5D routing matrix<ul>
<li>on the fly routing patching control</li>
<li>log of interactions affords easy real-time scripting interface<ul>
<li>'limiter' of too much clipping could undo last interaction from log?<ul>
<li>although this only works if feedback was caused by digital interaction, not change to audio in</li>
<li>sequencer interface for phone</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>stopping at the places in between</li>
<li>walking soundscape<ul>
<li>footstep rhythm</li>
<li>car drone<ul>
<li>how to work with?</li>
</ul>
</li>
</ul>
</li>
<li>[x] make marker in patch</li>
<li>pd log</li>
<li>ma - empty containers</li>
<li>rhythmic moving playheads<ul>
<li>how to deal with clicks?<ul>
<li>[x] pd-smoother (envelope)</li>
</ul>
</li>
</ul>
</li>
<li>buffer recorder recalls ephemeral moments</li>
<li>moving image as lo-fi sound processor/convolver</li>
<li>ultralight setup<ul>
<li>[x] pd x mobmuplat</li>
</ul>
</li>
<li>diffusion and routing as percussion (ambisonic/further away/filtered)</li>
<li>emergence in gifs, live-arppegio-code</li>
<li>emergence on the border of control</li>
<li>sound object delay line... blurring figure-ground by delaying figure-ground<ul>
<li>[x]</li>
<li>delayline changing speed can be octave/interval</li>
<li>moving delayline as rhythmic/textural harmonizer</li>
<li>gesture -&gt; rhythmic delay texture</li>
<li>slow gestures as play with space/time</li>
<li>texture from multiple delay lines,</li>
<li>delay line, listening again</li>
<li>when changing delay line length, fade it out / have variable gain</li>
</ul>
</li>
<li>environmental music: amplifying/using what is already there<ul>
<li>attention restoration theory</li>
<li>walk every day</li>
</ul>
</li>
</ul>
  </div>
  <div class="date">2020.06.14   <a href="/masi/field-recording">field recording</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/ginsterpfad-ambience/">ginsterpfad ambience</a></h2>

  <div class="sf" id="2020-06-14_2055_ginsterpfad-ambience.ogg"></div>

  <div class="date">2020.06.14   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/routing-matrix-pt-2/">routing matrix pt. 2</a></h2>

  <div class="sf" id="2020-06-14_0939.ogg"></div>
  <div class="sf" id="2020-06-14_0959.ogg"></div>
  <div class="sf" id="2020-06-14_1022.ogg"></div>
  <div class="sf" id="2020-06-14_1306.ogg"></div>

  <div class="entry-content">
  <p>in situ slow-evolving conducting/scheduling</p>
<p>first thing in the morning, open up the routing-matrix patch from yesterday, pull in a looped piano recording.</p>
<p>filtered in feedback and filtered again.</p>
<pre><code>route tapeshift~:dac~ 1 10000
X
|
metro 125
|
route sf~:dac~ 1 0; route sf~:dac~ 0 0 10
</code></pre>

<p><a href="/masi/patches/routing-matrix/routing-matrix.pd">patch.pd</a></p>
  </div>
  <div class="date">2020.06.13   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/routing-matrix/">routing matrix</a></h2>

  <div class="sf" id="2020-06-13_1305.ogg"></div>
  <div class="sf" id="2020-06-13_1308.ogg"></div>
  <div class="sf" id="2020-06-13_1317.ogg"></div>
  <div class="sf" id="2020-06-13_1318.ogg"></div>
  <div class="sf" id="2020-06-13_1322.ogg"></div>
  <div class="sf" id="2020-06-13_1642.ogg"></div>
  <div class="sf" id="2020-06-13_1805_stadtwald-crickets.ogg"></div>
  <div class="sf" id="2020-06-13_2042.ogg"></div>
  <div class="sf" id="2020-06-13_2101.ogg"></div>

  <div class="entry-content">
  <p>routing matrix with variable fade-time working</p>
<p><a href="/masi/patches/routing-matrix/routing-matrix.pd">patch.pd</a></p>
<p>recordings feature prominent low-end ambience from traffic - how to use this? filter it out?</p>
  </div>
  <div class="date">2020.06.12   <a href="/masi/field-recording">field recording</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/wassermannsee/">Wassermannsee</a></h2>

  <div class="sf" id="2020-06-12_1119.ogg"></div>
  <div class="sf" id="2020-06-12_1128.ogg"></div>
  <div class="sf" id="2020-06-12_1856.ogg"></div>
  <div class="sf" id="2020-06-12_2034_Wassermannsee.ogg"></div>

  <div class="entry-content">
  <p>wind through reeds, loud ducks. off-recorder mics make cue-making (almost) silent.</p>
  </div>
  <div class="date">2020.06.11   <a href="/masi/field-recording">field recording</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/am-ginsterpfad/">Am Ginsterpfad</a></h2>

  <div class="sf" id="2020-06-11_2036.ogg"></div>
  <div class="sf" id="2020-06-11_2049.ogg"></div>
  <div class="sf" id="2020-06-11_2131.ogg"></div>
  <div class="sf" id="2020-06-12_1856.ogg"></div>

  <div class="entry-content">
  <p>walking soundscape, slowly-changing filters as attention-prompts. elements:</p>
<ul>
<li>footstep rhythm</li>
<li>how to deal with traffic drone?</li>
</ul>
  </div>
  <div class="date">2020.06.11   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/pd-in-the-park/">pd in the park</a></h2>

  <div class="sf" id="2020-06-11_2140.ogg"></div>

  <div class="entry-content">
  <p>how to work with droning car sounds? trying to reinforce/mask them with sinewave organ.</p>
<p><img alt="pd in the park screenshot" src="/masi/patches/2020-06-11_2140_pd-in-the-park.pd.png#pd-screenshot" /></p>
<p><a href="/masi/patches/2020-06-11_2140_pd-in-the-park.pd">pd in the park patch</a></p>
  </div>
  <div class="date">2020.06.09   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/fur-iem-graz/">für iem-graz</a></h2>

  <div class="sf" id="2020-06-09_121053.ogg"></div>

  <div class="entry-content">
  <p>and later, 23:52:</p>
<video src="/masi/media/2020-06-09_2352.mov" controls></video>
  </div>
  <div class="date">2020.06.07   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/ppgrainer-t03-organ/">[pp.grainer~] T03 organ</a></h2>

  <div class="sf" id="2020-06-07_122700.ogg"></div>
  <div class="sf" id="2020-06-07_1356.ogg"></div>
  <div class="sf" id="2020-06-07_145600.ogg"></div>
  <div class="sf" id="2020-06-07_194200_grainer-vox-test.ogg"></div>

  <div class="entry-content">
  <p>testing sequencer with pp.grainer~ and KHG organ sample</p>
<pre><code>process=khg-organ.wav:pp.grainer~
</code></pre>

<pre><code>[pp.grainer~]&lt;:([tapeshift~].[pan~].[fade~],2)
</code></pre>
  </div>
  <div class="date">2020.06.06   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/g01/">G01</a></h2>

  <div class="sf" id="2020-06-06_211452.ogg"></div>

  <div class="entry-content">
  <p>ma jumps on piano loops</p>
  </div>
  <div class="date">2020.06.06   <a href="/masi/pd">pd</a>  <a href="/masi/modules">modules</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/pd-smoother-t01/">[pd smoother] T01</a></h2>

  <div class="sf" id="2020-06-06_215730.ogg"></div>

  <div class="entry-content">
  <p>[pd smoother] handles timing for fading level to zero while changing playPos</p>
<p><img alt="screenshot of pd-smoother" src="/masi/patches/2020-06-06_smoother.pd.png#pd-screenshot" /></p>
  </div>
  <div class="date">2020.06.05   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/2020-06-05_102557/">2020-06-05_102557</a></h2>

  <div class="sf" id="2020-06-05_102557.ogg"></div>

  <div class="date">2020.06.04   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/2020-06-04_221410/">2020-06-04_221410</a></h2>

  <div class="sf" id="2020-06-04_221410.ogg"></div>

  <div class="entry-content">
  <p>patch notes: two asynchronous loops, one ma loop</p>
<p>tapeshift~ delay on live input</p>
<p>would be nice: easy control of tapeshift~ volume (at least)</p>
  </div>
  <div class="date">2020.05.30   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/krupp-gm7-and-the-dogs-outside/">krupp gm7 and the dogs outside</a></h2>

  <div class="sf" id="2020-05-30_142454.mp3"></div>

  <div class="entry-content">
  <p>testing chord with rhymthic 1/8 playpos jumping as carpet</p>
<p>listened through through schmalfußs tape-IR. consider feeding through, re-recording?</p>
<p>todo: add playpos-jumping module</p>
  </div>
  <div class="date">2020.05.25   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/2020-05-25_175236/">2020-05-25_175236</a></h2>

  <div class="sf" id="2020-05-25_175236.ogg"></div>

  <div class="entry-content">
  <p>past sound as rhythmic pulse</p>
<p>spring between random segments of the loop</p>
<pre><code>every 1/8, jumping 1/8*lengthOfLoop * random(8)
</code></pre>
  </div>
  <div class="date">2020.05.22   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/2020-05-22_174851/">2020-05-22_174851</a></h2>

  <div class="sf" id="2020-05-22_174851.ogg"></div>

  <div class="entry-content">
  <p>1 mic in room with piano with loops and tapeshift</p>
<p>fix:</p>
<ul>
<li>[x] changing cycle length after buffer loop is made removes sound</li>
</ul>
<p>todo:</p>
<ul>
<li>[x] autogenerate meta.md</li>
<li>[x] include file automatically</li>
<li>[x] include date automatically</li>
<li>[ ] convert to mp3?</li>
<li>[x] offer voice memo feature? /</li>
<li>[ ] auto-open text editor with meta file?</li>
</ul>
  </div>
  <div class="date">2020.05.20   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/buffer-looper-router/">Buffer Looper-Router</a></h2>

  <div class="sf" id="2020-05-20_1921.ogg"></div>

  <div class="entry-content">
  <p>getting back to the launchpad-looper-router-interface, checking that it works as expected after a few days away. testing with a sample</p>
<p>patch notes: sample (taiwan-junglebirds.wav) looped, buffer looped, routed into tape-shift effect with feedback, starting to find something, hit record</p>
<p>todo:</p>
<ul>
<li>[x] get input routing working, so that can happen on the pad</li>
<li>[ ] get resonanant filter+tapeshift also mapped to pad buttons</li>
<li>[x] add record button to launchpad</li>
</ul>
  </div>
  <div class="date">2020.03.10   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/trainsketch-taiwan/">Trainsketch Taiwan</a></h2>

  <div class="sf" id="2020-03-10_171703_taiwan-trainsketch.ogg"></div>

  <div class="entry-content">
  <p><a href="/masi/patches/taiwan-trainsketch.pd">taiwan-trainsketch.pd</a></p>
  </div>
  <div class="date">2020.02.15   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/trumpet-drone-in-wallraf-richartz-museum/">Trumpet Drone in Wallraf-Richartz Museum</a></h2>

  <div class="sf" id="2020-02-15_182316_felix-wallraf.ogg"></div>

  <div class="date">2020.02.14   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/crinkly-plastic-bag-water-sound/">crinkly plastic bag -> water sound</a></h2>

  <div class="sf" id="2020-02-14_200851_marie-plasticbag.ogg"></div>

  <div class="date">2020.02.02   <a href="/masi/pd">pd</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/sinepiano-drone/">sine/piano drone</a></h2>

  <div class="sf" id="2020-02-02_154031_sinedrone_1.ogg"></div>

  <div class="date">2019.12.07  /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/bozen/">Bozen</a></h2>

  <div class="sf" id="2019-12-07_Bozen_F01.ogg"></div>
  <div class="sf" id="2019-12-07_Bozen_F02.ogg"></div>

  <div class="entry-content">
  <p>(todo: insert visuals!)</p>
<p>A handheld zoom capturing a waterfalls fed through Microbrute sequenced filter formed the basis for later keyboard overdubs.</p>
  </div>
  <div class="date">2019.12.05   <a href="/masi/field-recording">field recording</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/bozen-t02/">Bozen T02</a></h2>

  <div class="sf" id="2019-12-05_122648-LR.ogg"></div>
  <div class="sf" id="2019-12-05_122912-LR.ogg"></div>
  <div class="sf" id="2019-12-05_122912-Tr1.ogg"></div>

  <div class="entry-content">
  <p><img alt="microbrute snow" src="/masi/media/2019-12-06.jpg" /><br />
<img alt="microbrute stream" src="/masi/media/2019-12-05_114608.jpg" /></p>
  </div>
  <div class="date">2019.12.03   <a href="/masi/field-recording">field recording</a>   /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/bozen-t01/">Bozen T01</a></h2>

  <div class="sf" id="2019-12-03_121832-Tr2.ogg"></div>
  <div class="sf" id="2019-12-03_122620-Tr2.ogg"></div>
  <div class="sf" id="2019-12-03_185142-LR.ogg"></div>
  <div class="sf" id="2019-12-03_185338-LR.ogg"></div>
  <div class="sf" id="2019-12-03_185454-LR.ogg"></div>

  <div class="date">2019.11.29  /<a href="/masi/category/sounds.html">sounds</a></div>
  <h2><a href="/masi/where-it-started/">where it started</a></h2>

  <div class="sf" id="2019-11-29_Soundscape2_paulstretch.mp3"></div>

  <div class="entry-content">
  <p>(todo: insert soundscape no. 2)</p>
<p>Looped trumpet and piano free play, and paulstretched snippet.</p>
  </div>
  </section>

  <section id="wavesurfer-gui">
    <div id="gui">
      <a id="flip" href="">toggle waveform</a><br>
      <a id="toggleChrome" href="">options</a>
       <div class="chrome" style="margin-bottom:0.5em; width:200px;">
        <button type="button"><label for="loginput">load log from disk</label></button>
        <input type="file" id="loginput" style="visibility:hidden;width:0px;"/>

        <button onclick="loadVid()" type="button">load vid</button>
        <button onclick="offsetRegions(-44.322)" type="button">offset regions</button>
        <button onclick="removeCloseRegions()" type="button">remove close regions</button>
        <button onclick="saveRegions()" type="button">save regions to disk</button>

        <button onclick="saveRegionsToServer()" type="button">save regions to server</button>
        <button onclick="exportReaperProject()" type="button">export rpp</button>
      </div>
    </div>

    <div id="panel">
      <section>
        <div id="waveform">
          <span id="sfname"></span>
          <div id="progress"></div>
        </div>
      </section>

      <div class="chrome">
        <button data-action="play">play/pause</button>
        zoom: <input data-action="zoom" type="range" min="1" max="400" value="0" style="width: 300px" />
        <span id="time-current">0:00</span> / <span id="time-total">0:00</span>
      </div>
      <input id = "inputtext" type="text" onkeyup="handle(event)">
    </div>

    <script src="/masi/theme/js/jquery-3.5.1.min.js"></script>
    <script src="/masi/theme/js/wavesurfer.js"></script>
    <script src="/masi/theme/js/wavesurfer.regions.min.js"></script>
    <script src="/masi/theme/js/wavesurfer.cursor.js"></script>
    <script src="/masi/theme/js/FileSaver.js"></script>
    <script src="/masi/theme/js/app.js"></script>
  </section>
</body>
</html>