<!DOCTYPE html>
<html>
<head>
    <title>Notes on _Analysing Audible Ecosystems and Emergent Sound Structures in DiScipio’s Music_ (Renaud Meric, Makis Solomos) - masi</title>
  <meta charset="utf-8" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Literata:regular,italic,bold|Roboto+Mono:wght@450">
  <link rel="stylesheet" type="text/css" href="/masi/theme/css/style.css">





</head>

<body>
  <section id="nav">
    <header>
      <h1><a href="/masi/">masi</a></h1>
    </header>
    <nav id="menu"><ul>
      <li><a href="/masi/about/">/about</a></li>
      <li><a href="/masi/category/annotator.html">/annotator</a></li>
      <li><a href="/masi/category/notes.html">/notes</a></li>
      <li><a href="/masi/category/sounds.html">/sounds</a></li>
      <li><a href="/masi/ul">//ul</a></li>
      <li><a href="/masi/field-recording">//field recording</a></li>
      <li><a href="/masi/pd">//pd</a></li>
      <li><a href="/masi/modules">//modules</a></li>
    </ul></nav>
  </section>

  <section id="content">
  <div class="date">2020.07.04 </div>
  <h2><a href="/masi/notes-on-_analysing-audible-ecosystems-and-emergent-sound-structures-in-discipios-music_-renaud-meric-makis-solomos/">Notes on _Analysing Audible Ecosystems and Emergent Sound Structures in DiScipio’s Music_ (Renaud Meric, Makis Solomos)</a></h2>


  <div class="entry-content">
  <h1>Emergence in audibly-structured soundscape</h1>
<pre><code class="dot">digraph G {
  rankdir=LR

  subgraph cluster_0 {
    label = &quot;situ.in/space&quot;
    audiosystem -&gt; &quot;imprint in space&quot; -&gt; &quot;perciever-performer&quot; -&gt; { audiosystem &quot;imprint in space&quot; }

    { &quot;imprint in space&quot; audiosystem } -&gt; &quot;field recorder&quot;
  }
}
</code></pre>

<p><em>Figure: Emergence in place-language improvisation</em></p>
<p>modules for real-time composition of audibly-structured soundscape</p>
<p>A theoretical counterpart to the notion of audible ecosystems is the idea of emergent sound structures. The macroform emerges from interactions of the microforms.</p>
<pre><code class="dot">digraph G{
  node [shape=oval, len=2];

  space -&gt; { &quot;perciever-performer&quot; } -&gt; space

  space -&gt; input
  &quot;perciever-performer&quot; -&gt; { input }

  subgraph cluster_0 {
    style=&quot;rounded, dotted&quot;
    label = &quot;real-time audio processor&quot;
    input -&gt; process -&gt; output
  }

  output -&gt; space

  label = &quot;emergent macroform from microform interaction&quot;

}
</code></pre>

<blockquote>
<p>While  composing  with  an  ecosystemic  approach,  the  composer  creates  an  audio system that interacts with the environment (i.e. space). This space, in which and from which music emerges, is also the listener’s space. Thus what emerges is the result of a confrontation between  the  listener’s  cognitive  system and  the  audio  system  used  in  the  musical  work.  The emergent  sound  is  difficult  to  define:  its  general  outline  is  unpredictable  and  unstable;  it  is dependent on a dynamic musical space, which is constructed by active listening and an active audio  system  simultaneously.</p>
<p>focusing on the ephemeral moment in which music emerges  in  the  interaction  between  the  listener  and  the  product  of  the  audio  system  inside  a specific space.</p>
<p>in reality, we don’t listen to sound but to its own “imprint” (empreinte), in the sense of the word developed by Georges Didi-Huberman (2008).</p>
</blockquote>
<p>A real-time composition is to let  "the  musical (macro-level)  structure  emerge  from  sound  itself  and  its  internal  organization  (micro-level)" [^1].</p>
<blockquote>
<p>in  his  own  music, Di  Scipio  opted  for  complex  dynamic  systems:  “Chaos  and  the dynamics of complex systems, as accessible with iterated numerical processes, represented for me a way to compose small sonic units such that a higher-level sonority would manifest itself in the process” (Di Scipio inAnderson, 2005)</p>
<p>In one of his first articles (Di Scipio, 1994), he elaborated a “theory of sonological  emergence”,  whereby  form  (macroform)  is  viewed  as  “a  process  of  timbre formation” (Di Scipio, 1994: 205)</p>
<p>The  idea  of  emergent  sound  structures  is  related  to  the  elaboration  of  a sub-symbolic theory.  In  the “theory  of  sonological  emergence”,  the  emergence  of  a  higher level  should happen  through  grains  and  samples,  neither  of  which  are  symbols,  as  they  are  located  on  a low level (cf. Di Scipio, 1994: 207). With composed interactions (cf. infra), Di Scipio puts the interaction at the signal level: all the information exchanges have a sonic nature (cf. Di Scipio, 2003:  272).  We  can  draw  a  parallel  between  this  strategy  and  the  model  of  emergence  in cognitive  science.  To  the  question  “What  is  cognition?”  the  “computationalist”  model answers “Data processing: the manipulation of symbols from rules” (Varela, 1996: 42), while the  emergence  model  answers  “The  emergence  of  global  states  in  a  network  of  simple components” (Varela, 1996: 77). Regarding music, the issue at stake here is as follows: if we want the higher level (the macroform) to appear as an emergence and not as an independent construction,  we  have  to  work  only  at  the  lower  level,  abandoning  the  intermediate  level, which is the level of symbols.</p>
<p>According to emergence theory, the emergence of sound structures is possible because of the fact that the composer develops systems (in the sense of cybernetics) close to living systems, which are characterized by their capacity for auto-organization</p>
</blockquote>
<p>[^1]: Renaud Meric, Makis Solomos: Analysing Audible Ecosystems and Emergent Sound Structures in DiScipio’s Music</p>
  </div>
  </section>

  <section id="wavesurfer-gui">
    <div id="gui">
      <a id="flip" href="">toggle waveform</a><br>
      <a id="toggleChrome" href="">options</a>
       <div class="chrome" style="margin-bottom:0.5em; width:200px;">
        <button type="button"><label for="loginput">load log from disk</label></button>
        <input type="file" id="loginput" style="visibility:hidden;width:0px;"/>

        <button onclick="loadVid()" type="button">load vid</button>
        <button onclick="offsetRegions(-44.322)" type="button">offset regions</button>
        <button onclick="removeCloseRegions()" type="button">remove close regions</button>
        <button onclick="saveRegions()" type="button">save regions to disk</button>

        <button onclick="saveRegionsToServer()" type="button">save regions to server</button>
        <button onclick="exportReaperProject()" type="button">export rpp</button>
      </div>
    </div>

    <div id="panel">
      <section>
        <div id="waveform">
          <span id="sfname"></span>
          <div id="progress"></div>
        </div>
      </section>

      <div class="chrome">
        <button data-action="play">play/pause</button>
        zoom: <input data-action="zoom" type="range" min="1" max="400" value="0" style="width: 300px" />
        <span id="time-current">0:00</span> / <span id="time-total">0:00</span>
      </div>
      <input id = "inputtext" type="text" onkeyup="handle(event)">
    </div>

    <script src="/masi/theme/js/jquery-3.5.1.min.js"></script>
    <script src="/masi/theme/js/wavesurfer.js"></script>
    <script src="/masi/theme/js/wavesurfer.regions.min.js"></script>
    <script src="/masi/theme/js/wavesurfer.cursor.js"></script>
    <script src="/masi/theme/js/FileSaver.js"></script>
    <script src="/masi/theme/js/app.js"></script>
  </section>
</body>
</html>